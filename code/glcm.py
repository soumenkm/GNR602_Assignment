import torch, datetime
import tqdm
import numpy as np
from typing import List, Tuple, Dict, Optional
from dataset import MillionAIDataset
import matplotlib.pyplot as plt
import matplotlib.gridspec as gridspec
from pathlib import Path

class EfficientGLCM:
    """
    Computes Gray Level Co-occurrence Matrices (GLCMs), local window mean intensity,
    and GLCM eigenvalues for texture analysis.

    Provides an efficient vectorized method for GLCM and mean computation using
    tensor unfolding. Allows extraction of eigenvalue features from the GLCMs and
    combining them with the mean feature for subsequent analysis (e.g., clustering).
    Includes visualization capabilities for the computed features.

    Attributes:
        num_levels (int): Number of gray levels (G) used for quantization and GLCM size.
        window_size (int): Side length of the square sliding window (Ws).
        distance (int): Pixel distance (d) for co-occurrence calculation.
        angles (List[float]): List of angles (in radians) for co-occurrence offsets.
        epsilon (float): Small value added for numerical stability during normalization.
        offsets (List[Tuple[int, int]]): Pre-calculated (dr, dc) offsets based on distance and angles.
        output_dir (Path): Directory where visualizations generated by this class are saved.
        rgb_image (Optional[torch.Tensor]): Stores the original RGB image tensor if provided.
        gray_image (Optional[torch.Tensor]): Stores the input grayscale image tensor.
        original_shape (Optional[Tuple]): Shape of the input grayscale tensor.
        rescaled_image (Optional[torch.Tensor]): Grayscale image rescaled to G levels.
        output_glcms (Optional[torch.Tensor]): Computed raw GLCM counts (H', W', G, G).
        mean_map (Optional[torch.Tensor]): Computed map of mean intensity within each window (H', W').
        eigenvalue_maps (Optional[torch.Tensor]): Computed sorted eigenvalues for each GLCM (H', W', G).
    """
    def __init__(self,
                 num_levels: int = 5,
                 window_size: int = 5,
                 distance: int = 1,
                 angles: List[float] = [0, np.pi/4, np.pi/2, 3*np.pi/4],
                 output_dir: str = "output/glcms",
                 epsilon: float = 1e-9
                 ):
        """
        Initializes the EfficientGLCM calculator.

        Args:
            num_levels (int): Number of gray levels (G), must be 5, 6, or 7.
            window_size (int): Side length of the sliding window (must be odd, >=3).
            distance (int): Pixel distance (d) for co-occurrence pairs (>=1).
            angles (List[float]): Angles (radians) for spatial offsets.
            output_dir (str): Directory to save visualizations.
            epsilon (float): Small value for numerical stability (e.g., normalization).
        """
        if num_levels not in [5, 6, 7]:
            raise ValueError("num_levels must be 5, 6, or 7.")
        if not isinstance(window_size, int) or window_size < 2 or window_size % 2 == 0:
            raise ValueError("window_size must be an odd integer >= 3 for centered windows")
        if not isinstance(distance, int) or distance < 1:
            raise ValueError("distance must be an integer >= 1")

        self.num_levels = num_levels
        self.window_size = window_size
        self.window_radius = window_size // 2
        self.distance = distance
        self.angles = angles
        self.epsilon = epsilon

        self.offsets = self._calculate_offsets(distance, angles)

        self.rgb_image = None
        self.gray_image = None
        self.original_shape = None
        self.rescaled_image = None
        self.output_glcms = None
        self.mean_map = None
        self.eigenvalue_maps = None

        self.output_dir = Path.cwd() / output_dir
        self.output_dir.mkdir(parents=True, exist_ok=True)
        print(f"Output dir for GLCM class visualizations: {self.output_dir}")

    def _calculate_offsets(self, distance: int, angles: List[float]) -> List[Tuple[int, int]]:
        """
        Calculates the (row, column) offsets for GLCM computation based on distance and angles.
        Ensures symmetric offsets are included.

        Args:
            distance (int): The distance 'd'.
            angles (List[float]): Angles in radians.

        Returns:
            List[Tuple[int, int]]: A list of unique (dr, dc) offset pairs.
        """
        offsets = []
        for angle in angles:
            dr = round(-distance * np.sin(angle))
            dc = round(distance * np.cos(angle))
            offsets.append((dr, dc))
            if (dr, dc) != (-dr, -dc) or angle == 0 or angle == np.pi:
                 offsets.append((-dr, -dc))
        return list(set(offsets))

    def _rescale_image(self, gray_tensor: torch.Tensor) -> torch.Tensor:
        """
        Rescales a grayscale tensor (assumed range 0-255) to the specified number of levels (0 to G-1).

        Args:
            gray_tensor (torch.Tensor): Input grayscale tensor, shape (1, H, W) or (H, W), dtype uint8.

        Returns:
            torch.Tensor: Rescaled tensor, shape (H, W), dtype uint8, values in [0, G-1].
        """
        if gray_tensor.dim() == 3 and gray_tensor.shape[0] == 1:
            gray_tensor = gray_tensor.squeeze(0)
        elif gray_tensor.dim() != 2:
             raise ValueError("Input gray_tensor must be (1, H, W) or (H, W)")
        if gray_tensor.dtype != torch.uint8:
             print("Warning: Input tensor is not uint8. Assuming range 0-255 for rescaling.")
             gray_tensor = gray_tensor.byte()
        rescaled = (gray_tensor.float() / 256.0) * self.num_levels
        rescaled = torch.floor(rescaled).clamp(0, self.num_levels - 1)
        return rescaled.byte()

    def _calculate_glcm_for_window_efficient(self, r_start: int, c_start: int) -> torch.Tensor:
        """
        Calculates the GLCM for a single window using vectorized operations (bincount).
        Primarily used as a helper or for naive computation methods.

        Args:
            r_start (int): Top row index of the window.
            c_start (int): Left column index of the window.

        Returns:
            torch.Tensor: The GxG GLCM tensor (int64) for the specified window.
        """
        if self.rescaled_image is None: raise RuntimeError("Rescaled image not available.")
        H, W = self.rescaled_image.shape
        G, WS = self.num_levels, self.window_size
        r_end, c_end = r_start + WS, c_start + WS
        if r_end > H or c_end > W: raise ValueError(f"Window exceeds bounds")
        window = self.rescaled_image[r_start:r_end, c_start:c_end]
        glcm = torch.zeros((G, G), dtype=torch.int64, device=window.device)
        for dr, dc in self.offsets:
            r1s, r1e = max(0, -dr), min(WS, WS - dr)
            c1s, c1e = max(0, -dc), min(WS, WS - dc)
            r2s, r2e = max(0, dr), min(WS, WS + dr)
            c2s, c2e = max(0, dc), min(WS, WS + dc)
            if r1s >= r1e or c1s >= c1e: continue
            v1, v2 = window[r1s:r1e, c1s:c1e], window[r2s:r2e, c2s:c2e]
            val1, val2 = v1.flatten(), v2.flatten()
            idx = (val1.long() * G + val2.long())
            counts = torch.bincount(idx, minlength=G * G)
            glcm += counts.view(G, G)
        return glcm

    def compute_glcms_efficient(self, image_item: Dict) -> torch.Tensor:
        """
        Computes GLCMs and the Mean map across all valid windows using a vectorized approach.
        This is the recommended method for computation. Stores results in instance attributes.

        Args:
            image_item (Dict): Dictionary containing at least 'gray_pixels' tensor (1, H, W or H, W).
                               Can optionally include 'rgb_pixels' (3, H, W) for storage.

        Returns:
            torch.Tensor: The computed GLCM tensor, shape (H', W', G, G). The mean map is
                          stored in `self.mean_map` (shape H', W').
        """
        if 'gray_pixels' not in image_item:
            raise ValueError("Input dictionary must contain 'gray_pixels' tensor.")

        gray_tensor = image_item['gray_pixels']
        self.rgb_image = image_item.get('rgb_pixels', None)
        self.gray_image = gray_tensor

        self.original_shape = gray_tensor.shape
        self.rescaled_image = self._rescale_image(gray_tensor)
        H, W = self.rescaled_image.shape
        G = self.num_levels
        WS = self.window_size
        device = self.rescaled_image.device

        out_H, out_W = H - WS + 1, W - WS + 1
        if out_H <= 0 or out_W <= 0:
             print(f"Warning: Window size ({WS}) > image dimensions ({H}x{W}). No GLCMs/Mean computed.")
             self.output_glcms = torch.zeros((0, 0, G, G), dtype=torch.int64, device=device)
             self.mean_map = torch.zeros((0, 0), dtype=torch.float32, device=device)
             return self.output_glcms

        print("Starting Efficient GLCM & Mean computation...")

        unfolded_rows = self.rescaled_image.unfold(0, WS, 1)
        all_windows = unfolded_rows.unfold(1, WS, 1).contiguous()

        self.mean_map = torch.mean(all_windows.float(), dim=(-2, -1))
        print(f"Computed Mean Map with shape: {self.mean_map.shape}")

        glcms_array = torch.zeros((out_H, out_W, G, G), dtype=torch.int64, device=device)

        for dr, dc in tqdm.tqdm(self.offsets, desc="Vectorized Offsets", colour="blue", leave=False):
            r1s, r1e = max(0, -dr), min(WS, WS - dr)
            c1s, c1e = max(0, -dc), min(WS, WS - dc)
            r2s, r2e = max(0, dr), min(WS, WS + dr)
            c2s, c2e = max(0, dc), min(WS, WS + dc)
            if r1s >= r1e or c1s >= c1e: continue
            v1 = all_windows[:, :, r1s:r1e, c1s:c1e]
            v2 = all_windows[:, :, r2s:r2e, c2s:c2e]
            val1 = v1.reshape(out_H, out_W, -1)
            val2 = v2.reshape(out_H, out_W, -1)
            idx = (val1.long() * G + val2.long())
            offset_flat = torch.zeros(out_H, out_W, G * G, dtype=torch.int64, device=device)
            src = torch.ones_like(idx, dtype=torch.int64)
            offset_flat.scatter_add_(dim=2, index=idx, src=src)
            glcms_array += offset_flat.view(out_H, out_W, G, G)

        print("Finished Efficient GLCM & Mean computation.")
        self.output_glcms = glcms_array
        return self.output_glcms

    def _normalize_glcms(self, glcm_tensor: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        Normalizes raw GLCM counts to represent joint probabilities. Handles zero sums.

        Args:
            glcm_tensor (Optional[torch.Tensor]): Input GLCM tensor (H', W', G, G).
                                                  Uses `self.output_glcms` if None.

        Returns:
            torch.Tensor: Normalized GLCM tensor (H', W', G, G), dtype float32.
        """
        if glcm_tensor is None:
            if self.output_glcms is None:
                raise ValueError("No GLCM tensor provided and self.output_glcms is None.")
            glcm_tensor = self.output_glcms

        glcm_float = glcm_tensor.float()
        glcm_sum = torch.sum(glcm_float, dim=(-2, -1), keepdim=True)
        normalized_glcms = glcm_float / (glcm_sum + self.epsilon)
        zero_sum_mask_2d = (glcm_sum.squeeze(-1).squeeze(-1) <= self.epsilon)
        normalized_glcms[zero_sum_mask_2d] = 0.0
        return normalized_glcms

    def extract_eigenvalue_features(self, glcm_tensor: Optional[torch.Tensor] = None) -> torch.Tensor:
        """
        Normalizes GLCMs and computes their eigenvalues, sorting them in descending order.
        Stores the result in `self.eigenvalue_maps`.

        Args:
            glcm_tensor (Optional[torch.Tensor]): Raw GLCM count tensor (H', W', G, G).
                                                  Uses `self.output_glcms` if None.

        Returns:
            torch.Tensor: Sorted eigenvalue maps tensor (H', W', G), dtype float32.
        """
        if glcm_tensor is None:
            if self.output_glcms is None: raise ValueError("No GLCM tensor available.")
            glcm_tensor = self.output_glcms
        if glcm_tensor.numel() == 0:
             print("Warning: GLCM tensor empty. Returning empty eigenvalues.")
             self.eigenvalue_maps = torch.empty((0, 0, self.num_levels), dtype=torch.float32, device=glcm_tensor.device)
             return self.eigenvalue_maps
        normalized_glcms = self._normalize_glcms(glcm_tensor)
        try:
            eigenvalues = torch.linalg.eigvalsh(normalized_glcms.cpu()).to(normalized_glcms.device)
        except Exception as e:
            print(f"Error during eigenvalue computation: {e}. Returning NaNs.")
            eigenvalues = torch.full(normalized_glcms.shape[:-1], float('nan'), device=normalized_glcms.device)

        sorted_eigenvalues, _ = torch.sort(eigenvalues, dim=-1, descending=True)
        sorted_eigenvalues = torch.nan_to_num(sorted_eigenvalues, nan=0.0)
        self.eigenvalue_maps = sorted_eigenvalues
        return self.eigenvalue_maps

    def get_combined_features(self, num_top_eigenvalues: Optional[int] = None) -> Optional[torch.Tensor]:
        """
        Combines the selected top N eigenvalues with the computed mean map feature.

        Requires `extract_eigenvalue_features` and the mean computation (e.g., via
        `compute_glcms_efficient`) to have been run first.

        Args:
            num_top_eigenvalues (Optional[int]): Number of top eigenvalues to include (1 to G).
                                                  If None, all G eigenvalues are used.

        Returns:
            Optional[torch.Tensor]: Combined feature tensor (H', W', N_top + 1) or None if
                                    prerequisite features are missing or shapes mismatch.
        """
        if self.eigenvalue_maps is None:
            print("Error: Eigenvalue maps not computed yet.")
            return None
        if self.mean_map is None:
             print("Error: Mean map not computed yet.")
             return None
        if self.eigenvalue_maps.shape[:2] != self.mean_map.shape[:2]:
             print("Error: Eigenvalue maps and mean map have incompatible shapes.")
             return None

        G_features = self.eigenvalue_maps.shape[-1]
        if num_top_eigenvalues is None:
            num_top_eigenvalues = G_features
        elif not (1 <= num_top_eigenvalues <= G_features):
            raise ValueError(f"num_top_eigenvalues must be between 1 and {G_features}")

        selected_eigen_features = self.eigenvalue_maps[..., :num_top_eigenvalues]
        mean_map_expanded = self.mean_map.unsqueeze(-1)
        combined = torch.cat((selected_eigen_features, mean_map_expanded.to(selected_eigen_features.device)), dim=-1) # Ensure same device
        print(f"Combined features generated with shape: {combined.shape}")
        return combined


    def visualize_all(self, index: int) -> None:
        """
        Visualizes and saves input RGB, input grayscale, all G eigenvalue maps, and the mean map.
        Requires relevant attributes (rgb_image, gray_image, eigenvalue_maps, mean_map) to be populated.

        Args:
            index (int): An index used for naming the saved output file.
        """
        if self.rgb_image is None: print("Warning: RGB image not available for visualization."); return
        if self.gray_image is None: print("Error: Grayscale image not available."); return
        if self.eigenvalue_maps is None: print("Error: Eigenvalue maps not available."); return
        if self.mean_map is None: print("Error: Mean map not available."); return
        if self.eigenvalue_maps.numel() == 0 or self.mean_map.numel() == 0:
            print("Cannot visualize empty feature maps."); return

        rgb_np = self.rgb_image.permute(1, 2, 0).cpu().numpy()
        if self.gray_image.dim() == 3: gray_np = self.gray_image.squeeze(0).cpu().numpy()
        else: gray_np = self.gray_image.cpu().numpy()
        eigen_maps_np = self.eigenvalue_maps.cpu().numpy()
        mean_map_np = self.mean_map.cpu().numpy()
        H_out, W_out, G = eigen_maps_np.shape

        num_eigen_maps = G
        num_total_plots = 2 + num_eigen_maps + 1
        cols = int(np.ceil(np.sqrt(num_total_plots)))
        rows = int(np.ceil(num_total_plots / cols))

        fig = plt.figure(figsize=(cols * 4, rows * 4))
        gs = gridspec.GridSpec(rows, cols, figure=fig)
        plot_count = 0

        ax_rgb = fig.add_subplot(gs[plot_count]); plot_count += 1
        ax_rgb.imshow(rgb_np); ax_rgb.set_title("Original RGB"); ax_rgb.axis('off')

        ax_gray = fig.add_subplot(gs[plot_count]); plot_count += 1
        ax_gray.imshow(gray_np, cmap='gray'); ax_gray.set_title("Input Gray (0-255)"); ax_gray.axis('off')

        for k in range(num_eigen_maps):
            if plot_count >= rows * cols: break
            ax_eigen = fig.add_subplot(gs[plot_count]); plot_count += 1
            eigen_map_k = eigen_maps_np[:, :, k]
            im = ax_eigen.imshow(eigen_map_k, cmap='viridis')
            title = f"Eigenvalue {k+1}"
            if k == 0: title += " (Lrg)"
            if k == G - 1: title += " (Sml)"
            ax_eigen.set_title(title); ax_eigen.axis('off')
            plt.colorbar(im, ax=ax_eigen, fraction=0.046, pad=0.04)

        if plot_count < rows * cols:
            ax_mean = fig.add_subplot(gs[plot_count]); plot_count += 1
            im_mean = ax_mean.imshow(mean_map_np, cmap='plasma')
            ax_mean.set_title("Mean Map (Rescaled Gray)"); ax_mean.axis('off')
            plt.colorbar(im_mean, ax=ax_mean, fraction=0.046, pad=0.04)

        while plot_count < rows * cols: fig.add_subplot(gs[plot_count]).axis('off'); plot_count += 1

        suptitle = f"Input Images & Feature Maps (G={self.num_levels}, WS={self.window_size}, D={self.distance})"
        fig.suptitle(suptitle, fontsize=14)
        fig.tight_layout(rect=[0, 0.03, 1, 0.95])
        save_filename = f"features_idx_{index}_G{self.num_levels}_WS{self.window_size}.png"
        final_save_path = self.output_dir / save_filename
        try: plt.savefig(final_save_path); print(f"Feature maps saved to {final_save_path}")
        except Exception as e: print(f"Error saving figure: {e}")
        plt.close(fig)


if __name__ == "__main__":
    try:
        from dataset import MillionAIDataset
        train_dataset = MillionAIDataset(frac=0.001, is_train=True, output_dir="output/images")
        index=3
        data_item = train_dataset[index]
    except ImportError:
        print("Warning: dataset.py not found. Using dummy data for testing glcm.py.")
        H_img, W_img = 64, 64
        dummy_rgb = torch.randint(0, 256, (3, H_img, W_img), dtype=torch.uint8)
        dummy_gray = torch.randint(0, 256, (1, H_img, W_img), dtype=torch.uint8)
        data_item = {"rgb_pixels": dummy_rgb, "gray_pixels": dummy_gray, "labels": "dummy_label"}
        index = "dummy"

    NUM_LEVELS = 5
    WINDOW_SIZE = 7
    DISTANCE = 1
    ANGLES = [0, np.pi/4, np.pi/2, 3*np.pi/4]

    glcm_calculator = EfficientGLCM(
        num_levels=NUM_LEVELS,
        window_size=WINDOW_SIZE,
        distance=DISTANCE,
        angles=ANGLES
    )

    print(f"Processing image with shape: {data_item['gray_pixels'].shape}")
    start_time = datetime.datetime.now()
    output_glcm_tensor = glcm_calculator.compute_glcms_efficient(data_item)
    eigenvalue_tensor = glcm_calculator.extract_eigenvalue_features()
    glcm_calculator.visualize_all(index=index)
    end_time = datetime.datetime.now()
    print(f"GLCM, Mean, Eigenvalue computation & visualization took: {end_time - start_time}")

    if glcm_calculator.mean_map is not None: print(f"Mean map shape: {glcm_calculator.mean_map.shape}")
    if glcm_calculator.eigenvalue_maps is not None: print(f"Eigenvalue maps shape: {glcm_calculator.eigenvalue_maps.shape}")

    if glcm_calculator.eigenvalue_maps is not None and glcm_calculator.mean_map is not None:
        print("\n--- Example: Get combined features ---")
        combined_feat_3 = glcm_calculator.get_combined_features(num_top_eigenvalues=3)
        if combined_feat_3 is not None: print(f"Shape using Top 3 + Mean: {combined_feat_3.shape}")

        combined_feat_all = glcm_calculator.get_combined_features(num_top_eigenvalues=None)
        if combined_feat_all is not None: print(f"Shape using All {NUM_LEVELS} + Mean: {combined_feat_all.shape}")